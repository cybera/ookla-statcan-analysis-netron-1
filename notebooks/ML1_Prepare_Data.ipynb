{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this notebook before the ML notebook\n",
    "* This notebook requires down_up_lat_tests_by_quarter_part[1-5].csv in the current directory\n",
    "* This notebook reads chunks of raw data and prepares a large feature_table \n",
    "* Runtime about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = pd.DataFrame()\n",
    "number_of_chunks = 5\n",
    "for idx in range(1, number_of_chunks+1):\n",
    "    time_data = pd.concat([time_data, pd.read_csv(f\"../data/hackathon/down_up_lat_tests_by_quarter_part{idx}.csv\")])\n",
    "    # time_data = pd.concat([time_data, pd.read_csv(f\"down_up_lat_tests_by_quarter_part{idx}.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_data.columns)\n",
    "print(time_data.shape)\n",
    "cols_to_drop = ['geometry','DAUID','PRUID','CDUID','CCSUID','CCSNAME','CSDUID','ERUID','SACCODE','CMAUID','CMAPUID','CMANAME','CMATYPE','CTUID','CTNAME','ADAUID','PCUID','PCPUID']\n",
    "time_data = time_data.drop(columns=cols_to_drop).reset_index(drop=True)\n",
    "print(time_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_cols = [col for col in time_data if col.startswith('d20')]\n",
    "up_cols = [col for col in time_data if col.startswith('u20')]\n",
    "lat_cols = [col for col in time_data if col.startswith('l20')]\n",
    "tests_cols = [col for col in time_data if col.startswith('t20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds n previous quarters given the curent year(y) and quarter(q)\n",
    "def training_quarters(y, q, n):\n",
    "    quarters = []\n",
    "    i=0\n",
    "    while i<5:\n",
    "        if q<=i:\n",
    "            i = 0\n",
    "            y = y-1\n",
    "            q=4\n",
    "        else:\n",
    "            quarters.append(str(y) + \"Q\" + str(q-i))\n",
    "            i=i+1\n",
    "            if len(quarters) == n:\n",
    "                return quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a quarter as target and add corresponding features using def training_quarters()\n",
    "feature_table = pd.DataFrame()\n",
    "print(feature_table.shape)\n",
    "\n",
    "n_train_quarter = 8\n",
    "n_quarter = n_train_quarter+1\n",
    "\n",
    "for year in range(2021, 2023):\n",
    "    new_table = time_data.drop(columns=down_cols+up_cols+lat_cols+tests_cols)\n",
    "    for quarter in range(1, 5):\n",
    "        quarters = training_quarters(year, quarter, n_quarter)\n",
    "        for i in range(n_quarter):\n",
    "            new_table[\"d_quarter\"+str(i)] = time_data[\"d\"+quarters[i]]\n",
    "            new_table[\"u_quarter\"+str(i)] = time_data[\"u\"+quarters[i]]\n",
    "            new_table[\"l_quarter\"+str(i)] = time_data[\"l\"+quarters[i]]\n",
    "            new_table[\"t_quarter\"+str(i)] = time_data[\"t\"+quarters[i]]\n",
    "\n",
    "        feature_table = pd.concat([feature_table, new_table], ignore_index=True)\n",
    "        print(feature_table.shape)\n",
    "\n",
    "year=2023\n",
    "quarter=1\n",
    "new_table = time_data.drop(columns=down_cols+up_cols+lat_cols+tests_cols)\n",
    "quarters = training_quarters(year, quarter, n_quarter)\n",
    "for i in range(n_quarter):\n",
    "    new_table[\"d_quarter\"+str(i)] = time_data[\"d\"+quarters[i]]\n",
    "    new_table[\"u_quarter\"+str(i)] = time_data[\"u\"+quarters[i]]\n",
    "    new_table[\"l_quarter\"+str(i)] = time_data[\"l\"+quarters[i]]\n",
    "    new_table[\"t_quarter\"+str(i)] = time_data[\"t\"+quarters[i]]\n",
    "\n",
    "feature_table = pd.concat([feature_table, new_table], ignore_index=True)\n",
    "print(feature_table.shape) # Watch the feature table become larger with each new quarter as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 90 seconds to save the csv file. over 1 GB file.\n",
    "feature_table.to_csv(\"../data/hackathon/feature_table_by_quarter.csv\", index=False)\n",
    "# feature_table.to_csv(\"feature_table_by_quarter.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ookla-statcan-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
