{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML notebook\n",
    "* Some notes are marked down below important figures\n",
    "* Runtime about two minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and load dataset\n",
    "Run this section only once per kernel instance. A copy of the original dataset is passed to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes half a minute to load\n",
    "features_table = pd.read_csv(f\"../data/hackathon/feature_table_by_quarter.csv\") # Over a GB file size\n",
    "# features_table = pd.read_csv(f\"feature_table_by_quarter.csv\") # Over a GB file size\n",
    "features_table_bck = features_table.copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features ending with quarter0 are the target variables. Precedding features end with quarter1, quarter2...\n",
    "\n",
    "Features (number 17 onwards) have a prefix d_ for download speed, u_ for upload speed, l_ for latency, t_ for tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_table = features_table_bck.copy(deep=True)\n",
    "for i, col in enumerate(features_table.columns):\n",
    "    print(i,col)\n",
    "# print(features_table.head())\n",
    "# features_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkey = 'quadkey'\n",
    "#geometry = 'geometry'\n",
    "id_and_names = ['DAUID', 'CDUID', 'CDNAME', 'CCSUID', 'CSDNAME', 'CMAUID', 'CMAPUID', 'CMANAME', \n",
    "'CCSNAME', 'CSDUID', 'ERUID', 'ERNAME', 'CTUID', 'CTNAME', 'ADAUID', \n",
    "'PCUID', 'PCNAME', 'PCPUID', 'SACCODE'] ##SACCODE is half a category half ID values\n",
    "\n",
    "categorical_labels = [\n",
    "    #'PRUID', #PRUID is redundant with PRNAME\n",
    "    'CDNAME', 'CSDNAME',\n",
    "    'PRNAME', 'CDTYPE', \n",
    "    'CSDTYPE',  \n",
    "    'SACTYPE', \n",
    "    'PCNAME', 'PCTYPE', 'PCCLASS'\n",
    "]\n",
    "numerical_vars = [\n",
    "    'das_area', 'tile_area', 'tile_frac',  'das_frac', \n",
    "    'DAPOP','POP_DENSITY'\n",
    "]\n",
    "\n",
    "down_cols = [col for col in features_table if col.startswith('d_quarter')]\n",
    "up_cols = [col for col in features_table if col.startswith('u_quarter')]\n",
    "lat_cols = [col for col in features_table if col.startswith('l_quarter')]\n",
    "tests_cols = [col for col in features_table if col.startswith('t_quarter')]\n",
    "\n",
    "ookla_vars = down_cols + up_cols + lat_cols +tests_cols\n",
    "\n",
    "target_vars = ['d_quarter0', 'u_quarter0', 'l_quarter0', 't_quarter0']\n",
    "\n",
    "ookla_vars = [col for col in ookla_vars if col not in target_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = [pkey] + categorical_labels + numerical_vars + ookla_vars + target_vars\n",
    "print(features_table.shape)\n",
    "features_table = features_table.loc[:,col_subset].set_index('quadkey').dropna()\n",
    "#print(features_table.isna().sum())\n",
    "print(features_table.shape) # Compare with the previous shape to see how many rows/cols are dropped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, pipeline, compose\n",
    "from sklearn import linear_model, model_selection, svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard train/test where down and/or up speeds are the target/predicted continuous variable.\n",
    "X_train, X_test, down_train, down_test = model_selection.train_test_split(\n",
    "    features_table.drop(columns=target_vars), features_table['d_quarter0']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_table.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(down_train.shape)\n",
    "print(down_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the numerical Data and OneHot encode the categorical vars.\n",
    "colTransformer = compose.ColumnTransformer(\n",
    "    [(f\"{cat}\",preprocessing.OneHotEncoder(handle_unknown='ignore'),[cat]) for cat in categorical_labels] +\\\n",
    "    [(f\"{num}\", preprocessing.StandardScaler(), [num]) for num in numerical_vars] +\\\n",
    "    [(f\"{num}\", preprocessing.StandardScaler(), [num]) for num in ookla_vars]\n",
    "    #+ [(f\"{y}_stdscaler\", preprocessing.StandardScaler(), [y]) for y in target_vars]\n",
    ")\n",
    "\n",
    "#Setup a regressor for predicting down speeds.\n",
    "ridge = linear_model.RidgeCV()\n",
    "regressor = compose.TransformedTargetRegressor(\n",
    "    regressor=ridge,\n",
    "    transformer=preprocessing.PowerTransformer(method='box-cox')\n",
    ")\n",
    "\n",
    "# Combine above in a reuseable pipeline object\n",
    "pipe = pipeline.Pipeline([\n",
    "    ('preprocess',colTransformer),\n",
    "    ('regressor', regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "pipe.fit(X_train, down_train) # Takes 100 seconds to fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did it do on the training set\n",
    "# speeds are in kbps\n",
    "{\"Mean Absolute Error\":metrics.mean_absolute_error(pipe.predict(X_train), down_train),\n",
    "\"Median Absolute Error\":metrics.median_absolute_error(pipe.predict(X_train), down_train),\n",
    "\"Mean Absolute Percentage Error\":metrics.mean_absolute_percentage_error(pipe.predict(X_train), down_train)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gives low percentage error, but the predictions are normally distributed.\n",
    "* Input data is normally distributed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(14,6))\n",
    "axs[0].scatter(down_train, pipe.predict(X_train), alpha=0.05);\n",
    "axs[0].set(xlabel=\"Measured Download Speed (kbps)\", ylabel=\"Predicted Download Speed (kbps)\");\n",
    "\n",
    "bins = np.linspace(-60000,800000,100)\n",
    "axs[1].hist(down_train,alpha=0.5, bins=bins,label='Measured Data')\n",
    "axs[1].hist(pipe.predict(X_train),alpha=0.5, bins=bins,label='Predicted Data');\n",
    "axs[1].legend()\n",
    "axs[1].set(xlabel='Download Speed (kbps)', ylabel='Tile Count (N)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "bins = np.linspace(-60000,800000,100)\n",
    "axs[0].hist(down_train,alpha=0.5, bins=bins,label='Actual_train')\n",
    "axs[0].hist(pipe.predict(X_train),alpha=0.5, bins=bins,label='Predicted_train');\n",
    "axs[0].legend()\n",
    "axs[0].set(xlabel='Download Speed (kbps)', ylabel='Tile Count (N)');\n",
    "\n",
    "bins = np.linspace(-60000,800000,100)\n",
    "axs[1].hist(down_test,alpha=0.5, bins=bins,label='Actual_test')\n",
    "axs[1].hist(pipe.predict(X_test),alpha=0.5, bins=bins,label='Predicted_test');\n",
    "axs[1].legend()\n",
    "axs[1].set(xlabel='Download Speed (kbps)', ylabel='Tile Count (N)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the important coefficients.\n",
    "coefs = pd.DataFrame(pipe[-1].regressor_.coef_,columns=['Coefficients'],index=pipe[:-1].get_feature_names_out())\n",
    "coefs = coefs[np.abs(coefs.values) > 0.33]\n",
    "coefs.sort_values(by='Coefficients').plot.barh(figsize=(8,6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some categorical features cancel each other out.\n",
    "* Why no speed column has high coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the previous year speed data.\n",
    "coefs = pd.DataFrame(pipe[-1].regressor_.coef_,columns=['Coefficients'],index=pipe[:-1].get_feature_names_out())\n",
    "coefs = coefs[coefs.index.isin([f\"{col}__{col}\" for col in ookla_vars])]\n",
    "ax = coefs.sort_values(by='Coefficients').plot.barh(figsize=(8,10))\n",
    "ax2 = ax.secondary_xaxis('top')\n",
    "ax2 = coefs.sort_values(by='Coefficients').plot.barh(figsize=(8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model has indeed learned stuff\n",
    "    * Uses previous download speeds to predict future download speeds\n",
    "    * The most recent data is evaluated more important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ookla-statcan-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
